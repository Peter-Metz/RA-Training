{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data analysis with Pandas and Numpy\n",
    "\n",
    "## 1. Numpy\n",
    "\n",
    "Numpy is a powerful Python package for manipulating numerical data structures called arrays. The name numpy stands for \"numerical Python\".\n",
    "\n",
    "A vector and a matrix are both examples of arrays. A vector is a one-dimensional array, and a matrix is a two-dimensional array. In numerical methods, one will often want to organize and manipulate data that has many dimensions. Arrays are the ideal Euclidean structure for numerical data.\n",
    "\n",
    "Numpy is an essential package for working with numerical data. Even though you can often perform the operations you would like to execute with Python's native data types, numpy will often provide the most convenient and efficient functionality.\n",
    "\n",
    "We can create a 1-dimensional numpy array by importing numpy and using the `array()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr1 = np.array([8, 4, 6, 0, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a two-dimensional array\n",
    "arr2 = np.array([[1, 2, 3], [4, 5, 6]])\n",
    "# attribute\n",
    "arr2.shape\n",
    "# method\n",
    "arr2.sum()\n",
    "type(arr2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can slice elements of the array with numpy's indexing. The indexing is such that the first dimension is rows, the second dimension is columns, and every other dimension is not geometrically represented. As with all of Python, the first element's index number is 0. If you want a slice from the mth element to the nth element, you must use m: n+1. Further\n",
    "\n",
    "- a scalar m means the m+1th element\n",
    "- an empty : means the entire dimension\n",
    "- two colons followed by an integer ::p means every pth element\n",
    "- a colon followed by an integer :n gives a slice from the first element to the nth element.\n",
    "- an integer followd by a colon m: gives a slice from the m+1th element to the last element."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr2[0]\n",
    "arr2[1,1]\n",
    "arr2[:,1]\n",
    "arr2[0,:]\n",
    "arr2[-1, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic arithmetic\n",
    "arr3 = np.array([[10,8,6], [4,2,0]])\n",
    "arr2 + arr3\n",
    "arr2 * arr3\n",
    "arr2 + 2\n",
    "arr2 < 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numpy has lots of built-in functions. In this example, we create a vector called `dependents` of 20 random integers [0, 6) that represent number of dependents. Since the EITC can only be applied to up to 3 dependents, we create a new vector called `eitc_qual` that uses the `minimum` method to take the minimum of each element in `dependents` and 3.\n",
    "\n",
    "NOTE: we could have imported the randint method with:\n",
    "\n",
    "```python\n",
    "from numpy import random as rd\n",
    "dependents = rd.randint(0,6,20)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dependents = np.random.randint(0,6,20)\n",
    "eitc_qual = np.minimum(dependents, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can think of `np.where` as an if-statement. The first argument is the condition, the second is the result if the condition is met, and the third is the result if the condition is not met."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mstat = np.array(['single', 'joint', 'joint', 'single', 'single'])\n",
    "num_taxpayers = np.where(mstat=='single', 1, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  2. Pandas\n",
    "\n",
    "Pandas is another Python package for data analysis. Pandas two main data structures are the `Series` object and the `DataFrame` object. For now, we will focus on the `DataFrame` object.\n",
    "\n",
    "The `DataFrame` is the standard data structure that you would think of when using programs like Stata, SAS, or R. As with the univariate Series object, the DataFrame allows for traditional data analysis facility while interacting with all of Python's other functionality. You will notice that many of the methods available to pandas `DataFrames` are also available in `numpy`. Their methods are usually equivalent, but the advantage of performing operations with the `DataFrame` is its respect for the index values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# there are multiple ways to create a DataFrame. Here, we convert a dictionary to a DataFrame \n",
    "data = {'state': ['Ohio', 'Ohio', 'Ohio', 'Nevada', 'Nevada'],\n",
    "        'year': [2000, 2001, 2002, 2001, 2002],\n",
    "        'pop': [1.5, 1.7, 3.6, 2.4, 2.9]}\n",
    "frame = pd.DataFrame(data)\n",
    "# attributes\n",
    "frame.index\n",
    "frame.columns\n",
    "frame.shape\n",
    "# copying DataFrame\n",
    "frame2 = frame.copy()\n",
    "# one way to add a column\n",
    "region = ['East', 'East', 'East', 'West', 'West']\n",
    "frame2['Region'] = region\n",
    "# a better way to add a column using np.where\n",
    "frame['Region'] = np.where(frame['State']=='Ohio', 'East', 'West')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of manually creating the data for the DataFrame, let's read a csv file into a Pandas DataFrame using the `read_csv()` method. The mandatory argument is a string of the file path to the csv (relative to where you Jupyter Notebook or Python script is saved). In this case, we have saved `weather.csv` to the same folder as this Notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_df = pd.read_csv('weather.csv')\n",
    "# the default index is 0, 1, 2... We can set the YEAR column as our index for readability.\n",
    "weather_df2 = weather_df.set_index('YEAR')\n",
    "weather_df2.index\n",
    "# use the describe() method to get a sense of the data\n",
    "describe_df = weather_df2.describe()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
